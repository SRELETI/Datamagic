#!/usr/bin/env python 3.3

import os
import re
import json
from abc import ABCMeta, abstractmethod
import shutil
from Db import db_interface

# Parses the files which are generated by the Crawler
class Parser(metaclass=ABCMeta):
    def __init__(self,preprocess_dir,processed_dir):
        self.preprocess_dir=preprocess_dir
        self.processed_dir=processed_dir
        # Creates directory if no directory exists previously 
        try:
            os.makedirs(self.preprocess_dir)
            os.makedirs(self.processed_dir)
        # If already exists, just skips 
        except OSError:
            pass
        
    # The carriage return in removed here 
    def remove_carriage_return(self,file):
        # opens the file in the format utf-8
        file_open= open(file,'r',encoding='utf-8')
        # reads the file contents and stores in a string
        contents=file_open.read()
        # closes the file
        file_open.close()
        # carriage return removed here
        contents=re.sub(r'\r\n?','\n',contents)
        return contents

    # calls the function to remove carriage return
    def pre_process(self,file):
        contents=self.remove_carriage_return(file)
        return contents
    # Moves the processed file from preprocess directory to processed directory and inserts data into the database
    def post_process(self,file,json_list):
        # Move the file from preprocess directory to processed directory
        shutil.move(os.path.join(self.preprocess_dir,file),os.path.join(self.processed_dir,file))
        # Connect to the database
        db=db_interface()
        # If empty, just return 
        if json_list == None:
            return
        #insert into the database
        for json in json_list:
            db.put(json)
            #print (json)

        
    def execute(self):
        # Gives all the files, sub directories in the preprocess_dir
        listing=os.listdir(self.preprocess_dir)
        # Loop over the files in the listing
        for file in listing:
            # Process each file 
            f=self.pre_process(os.path.join(self.preprocess_dir,file))
            json_data=self.parse(f)
            self.post_process(file,json_data)
            
    def parse(self,contents):
        pass
        # The subclass takes care, sub class responsibility



#sample_parser=Parser(r'C:\Users\sudeep\WRPS_DATA\PYTHON\current_incident\preprocess',r'C:\Users\sudeep\WRPS_DATA\PYTHON\current_incident\processed')
#sample_parser.execute()       
